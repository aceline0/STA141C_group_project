{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression via Newton's Method\n",
    "\n",
    "* Newton's Method Functions:  \n",
    "     - **logfunc(x)**: finds the logistic function  $$f(x) = \\frac{1}{1+e^{-\\beta^Tx}}$$\n",
    "     - **newton_method_lrstep(beta0,y,X)**: Updates Newton's Method, $$\\beta^{(t+1)} = \\beta^{(t)} + H^{-1}\\nabla{l(\\beta)}$$  where $l(\\beta)$ is the log-likelihood of $\\beta$ for a Logistic Regression  \n",
    "     - **tolerance_check(beta0,beta,eps)**: Checks if it converges to a set threshold, $$|\\beta^{(t)}-\\beta^{t+1}|<\\epsilon$$\n",
    "     - **newton_method_logreg(beta0,y,X,eps)**: Newton's Method for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as linalg \n",
    "\n",
    "def logfun(x): # logistic function\n",
    "    p = 1/(1+np.exp(-x)) # probability\n",
    "    return p\n",
    "\n",
    "def newton_method_lrstep(beta0,y,X, method):\n",
    "    betaX = np.dot(X,beta0) # beta*X\n",
    "    yx = logfun(betaX) # y_hat\n",
    "    y_hat = np.array(yx,ndmin=2) # converts to y_hat array\n",
    "    gradient = np.dot(X.T, (y-y_hat)) # gradient\n",
    "\n",
    "    ny_hat = 1-y_hat\n",
    "    d = np.dot(y_hat,ny_hat.T)\n",
    "    diag = np.diag(d)\n",
    "    d = np.diag(diag)\n",
    "    hessian = X.to_numpy().T.dot(d).dot(X.to_numpy()) # hessian matrix\n",
    "    if method == \"LU\":\n",
    "        hessian_inv = np.linalg.inv(hessian)\n",
    "    elif method == \"QR\":\n",
    "        n = hessian.shape[1]\n",
    "        Q,R = np.linalg.qr(hessian)\n",
    "        Rinv = linalg.solve_triangular(R,np.identity(n))\n",
    "        hessian_inv = np.dot(Rinv,Q.T)\n",
    "    else:\n",
    "        hessian_inv = np.linalg.inv(hessian) ## REPLACE FOR CHOLEVSKY DECOMPOSITION ##\n",
    "\n",
    "    gd = np.dot(hessian_inv,gradient) # finds the step direction\n",
    "\n",
    "    beta = beta0 + gd # updates coefficients\n",
    "\n",
    "    return beta\n",
    "\n",
    "def tolerance_check(beta0, beta, eps):\n",
    "    diff = np.abs(beta0-beta) # norm \n",
    "    if np.any(diff>eps): # if norm crosses threshold\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def newton_method_logreg(beta0, y, X,eps,method):\n",
    "    iterations = 0 # initial iterations\n",
    "    converge = False # sets converge to false\n",
    "    while not converge: # while converge is false\n",
    "        beta = newton_method_lrstep(beta0,y,X,method) # finds new beta\n",
    "        converge = tolerance_check(beta0,beta,eps) # checks convergence\n",
    "        beta0 = beta # updates beta\n",
    "        iterations +=1 # updates iterations\n",
    "        print (\"Iteration: {}\".format(iterations))\n",
    "    return beta\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Dataset**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dropout = pd.read_csv(\"../Datasets/schooldropout.csv\", sep=\";\")\n",
    "dropout['Target'].replace(['Dropout', 'Graduate',\"Enrolled\"],[0, 1,1], inplace=True)\n",
    "\n",
    "X = dropout.drop(['Target'],axis=1)\n",
    "y = dropout[[\"Target\"]]\n",
    "\n",
    "X_train,x_test,y_train, y_test = train_test_split(X,y ,random_state=100, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.00058713e-01],\n",
       "       [-1.44829319e-03],\n",
       "       [-8.47128733e-02],\n",
       "       [-1.01993413e-04],\n",
       "       [ 5.03734035e-02],\n",
       "       [ 1.08353844e-02],\n",
       "       [-4.21872230e-03],\n",
       "       [-3.82197232e-02],\n",
       "       [-1.43403009e-02],\n",
       "       [ 9.19269825e-03],\n",
       "       [ 1.51162903e-02],\n",
       "       [-5.78843199e-03],\n",
       "       [ 5.43759909e-03],\n",
       "       [-2.74915159e-01],\n",
       "       [-5.27119976e-01],\n",
       "       [-4.45410756e-01],\n",
       "       [ 2.30739391e+00],\n",
       "       [-2.11933927e-01],\n",
       "       [ 5.93439044e-01],\n",
       "       [-4.43493981e-02],\n",
       "       [ 2.25226491e+00],\n",
       "       [-1.07333893e-01],\n",
       "       [-2.08974485e-02],\n",
       "       [ 1.92732815e-02],\n",
       "       [ 2.81507878e-01],\n",
       "       [-6.37193801e-02],\n",
       "       [ 1.21422582e-01],\n",
       "       [-2.30988212e-01],\n",
       "       [-4.61497530e-01],\n",
       "       [ 3.50939614e-02],\n",
       "       [ 6.06727214e-01],\n",
       "       [ 7.87625927e-02],\n",
       "       [ 1.06016918e-01],\n",
       "       [-5.48824012e-02],\n",
       "       [-1.19697421e-02],\n",
       "       [ 2.05755568e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta0 = np.zeros((36,1))\n",
    "eps = 10**(-3)\n",
    "beta = newton_method_logreg(beta0,y_train,X_train,eps,method=\"LU\")\n",
    "beta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.315118\n",
      "         Iterations 7\n",
      "                                        Results: Logit\n",
      "==============================================================================================\n",
      "Model:                        Logit                      Pseudo R-squared:           0.501    \n",
      "Dependent Variable:           Target                     AIC:                        2302.4074\n",
      "Date:                         2023-03-15 18:33           BIC:                        2524.5850\n",
      "No. Observations:             3539                       Log-Likelihood:             -1115.2  \n",
      "Df Model:                     35                         LL-Null:                    -2236.6  \n",
      "Df Residuals:                 3503                       LLR p-value:                0.0000   \n",
      "Converged:                    1.0000                     Scale:                      1.0000   \n",
      "No. Iterations:               7.0000                                                          \n",
      "----------------------------------------------------------------------------------------------\n",
      "                                                Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Marital status                                  0.2001   0.1140  1.7554 0.0792 -0.0233  0.4234\n",
      "Application mode                               -0.0014   0.0042 -0.3480 0.7278 -0.0096  0.0067\n",
      "Application order                              -0.0847   0.0466 -1.8181 0.0690 -0.1760  0.0066\n",
      "Course                                         -0.0001   0.0000 -2.6514 0.0080 -0.0002 -0.0000\n",
      "Daytime/evening attendance                      0.0504   0.1877  0.2684 0.7884 -0.3175  0.4183\n",
      "Previous qualification                          0.0108   0.0061  1.7697 0.0768 -0.0012  0.0228\n",
      "Previous qualification (grade)                 -0.0042   0.0046 -0.9221 0.3565 -0.0132  0.0047\n",
      "Nationality                                    -0.0382   0.0113 -3.3910 0.0007 -0.0603 -0.0161\n",
      "Mother's qualification                         -0.0143   0.0044 -3.2376 0.0012 -0.0230 -0.0057\n",
      "Father's qualification                          0.0092   0.0043  2.1265 0.0335  0.0007  0.0177\n",
      "Mother's occupation                             0.0151   0.0054  2.7937 0.0052  0.0045  0.0257\n",
      "Father's occupation                            -0.0058   0.0055 -1.0433 0.2968 -0.0167  0.0051\n",
      "Admission grade                                 0.0054   0.0045  1.2118 0.2256 -0.0034  0.0142\n",
      "Displaced                                      -0.2749   0.1269 -2.1668 0.0302 -0.5236 -0.0262\n",
      "Educational special needs                      -0.5271   0.4697 -1.1222 0.2618 -1.4478  0.3935\n",
      "Debtor                                         -0.4454   0.1840 -2.4206 0.0155 -0.8061 -0.0848\n",
      "Tuition fees up to date                         2.3074   0.1975 11.6836 0.0000  1.9203  2.6945\n",
      "Gender                                         -0.2119   0.1170 -1.8108 0.0702 -0.4413  0.0175\n",
      "Scholarship holder                              0.5934   0.1544  3.8445 0.0001  0.2909  0.8960\n",
      "Age at enrollment                              -0.0443   0.0102 -4.3627 0.0000 -0.0643 -0.0244\n",
      "International                                   2.2523   0.6567  3.4298 0.0006  0.9652  3.5393\n",
      "Curricular units 1st sem (credited)            -0.1073   0.0886 -1.2110 0.2259 -0.2810  0.0664\n",
      "Curricular units 1st sem (enrolled)            -0.0209   0.1102 -0.1896 0.8496 -0.2369  0.1951\n",
      "Curricular units 1st sem (evaluations)          0.0193   0.0270  0.7138 0.4753 -0.0336  0.0722\n",
      "Curricular units 1st sem (approved)             0.2815   0.0577  4.8790 0.0000  0.1684  0.3946\n",
      "Curricular units 1st sem (grade)               -0.0637   0.0265 -2.4037 0.0162 -0.1157 -0.0118\n",
      "Curricular units 1st sem (without evaluations)  0.1214   0.1073  1.1314 0.2579 -0.0889  0.3318\n",
      "Curricular units 2nd sem (credited)            -0.2310   0.0959 -2.4095 0.0160 -0.4189 -0.0431\n",
      "Curricular units 2nd sem (enrolled)            -0.4615   0.1065 -4.3339 0.0000 -0.6702 -0.2528\n",
      "Curricular units 2nd sem (evaluations)          0.0351   0.0252  1.3947 0.1631 -0.0142  0.0844\n",
      "Curricular units 2nd sem (approved)             0.6067   0.0529 11.4785 0.0000  0.5031  0.7103\n",
      "Curricular units 2nd sem (grade)                0.0788   0.0250  3.1553 0.0016  0.0298  0.1277\n",
      "Curricular units 2nd sem (without evaluations)  0.1060   0.0878  1.2080 0.2270 -0.0660  0.2780\n",
      "Unemployment rate                              -0.0549   0.0218 -2.5187 0.0118 -0.0976 -0.0122\n",
      "Inflation rate                                 -0.0120   0.0398 -0.3007 0.7636 -0.0900  0.0660\n",
      "GDP                                             0.0206   0.0272  0.7575 0.4487 -0.0327  0.0738\n",
      "==============================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing**  \n",
    "Taken from online resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lr(X,y,beta):\n",
    "    xbeta = np.dot(X,beta)\n",
    "    predict = np.array(logfun(xbeta))\n",
    "    threshold = 0.5*np.ones((predict.shape[0],1))\n",
    "    pred_class = np.greater(predict,threshold)\n",
    "    accuracy = np.count_nonzero(np.equal(pred_class, y))/pred_class.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779661016949153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lr(x_test,y_test,beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
